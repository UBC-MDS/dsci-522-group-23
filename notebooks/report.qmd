---
title: Predicting academic performance using demographic and behavioral Data
jupyter: python3
author: "Zhengling Jiang, Colombe Tolokin, Franklin Aryee, Tien Nguyen"
format: 
    html:
        toc: true
        toc-depth: 4
        number-sections: true
        embed-resources: true
    pdf:
        toc: true
        toc-depth: 4
        number-sections: true
editor: source
# execute: 
#   echo: false
bibliography: references.bib
link-citations: true
---

```{python}
# | echo: false
import pandas as pd
import altair as alt
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import make_pipeline
from sklearn.compose import make_column_transformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import pandera as pa
from scipy.stats import shapiro
from sklearn.dummy import DummyRegressor
from sklearn.model_selection import cross_validate
from pathlib import Path

from IPython.display import Markdown

alt.renderers.enable("mimetype")
%matplotlib inline
```

```{python}
# | echo: False
metrics_table = pd.read_csv("../results/table/metrics/evaluation_metrics.csv")
mse = round(float(metrics_table.query('Metric == "Mean Squared Error (MSE)"')['Value'].iloc[0]), 3)
rmse = round(float(metrics_table.query('Metric == "Root Mean Squared Error (RMSE)"')['Value'].iloc[0]), 3)
mae = round(float(metrics_table.query('Metric == "Mean Absolute Error (MAE)"')['Value'].iloc[0]), 3)
```

```{python}
#| echo: false
gs = pd.read_csv("../results/plots/grid_search_results.csv")
best_alpha = round(float(gs.iloc[0, 2]), 2)
best_score = round(float(-gs.iloc[0, 1]), 3)
```

## Summary

This project investigates whether a student's mathematics performance can be predicted using demographic and behavioral data, aiming to help educators support students and tailor educational strategies. Using a Ridge Regression model with optimized hyperparameters **(alpha = `{python} best_alpha`)**, we achieved strong predictive accuracy with a **cross-validation score of `{python} best_score`** and evaluation metrics on the test set including an **MSE of `{python} mse`, RMSE of `{python} rmse`, and MAE of `{python} mae`**. The Ridge model was particularly suitable for this task as it effectively handles multicollinearity among features while maintaining model interpretability. While the model demonstrates robust performance, future work could explore non-linear models to capture more complex relationships and provide confidence intervals for predictions, enhancing the model's interpretability and reliability. These improvements could further support educators in making data-informed decisions to optimize student outcomes.

## Introduction

Math teaches us to think logically and it also provides us with analytical and problem-solving skills. These skills can be applied to various academic and professional fields. However, student performance in mathematics can be influenced by many factors, like individual factor, social factor, and family factor. Research has shown that attributes such as study habits, age, social behaviour (alcohol consumptions, etc) and family background can significantly impact a student's academic success. Understanding these factors is crucial for improving educational outcomes. (@bitrus2016marital, @hjarnaa2023alcohol, @modi2023)

In this study, we aim to address this question: **“Can we predict a student's math academic performance based on the demographic and behavioral data?”**. Answering this question is important because understanding the factors behind student performance can help teachers provide support to struggling students. Furthermore, the ability to predict academic performance could assist schools in developing educational strategies based on different backgrounds of students. The goal of this study is to develop a machine learning model capable of predicting student’s math performance with high accuracy.

The dataset (@student_performance) used in this study contains detailed records of student demographics and behaviors, such as age, study habits, social behaviors, and family background. The target variable, mathematics performance, is measured as a continuous score reflecting students' final grade. This dataset offers a great opportunity to explore meaningful relationships between features and academic outcomes.

## Methods & Results

The objective here to prepare the data for our classification analysis by exploring relevant features and summarizing key insights through data wrangling and visualization.

### Dataset Description

The full data set contains the following columns:

1.  `school` - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)
2.  `sex` - student's sex (binary: 'F' - female or 'M' - male)
3.  `age` - student's age (numeric: from 15 to 22)
4.  `address` - student's home address type (binary: 'U' - urban or 'R' - rural)
5.  `famsize` - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)
6.  `Pstatus` - parent's cohabitation status (binary: 'T' - living together or 'A' - apart)
7.  `Medu` - mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 - “ 5th to 9th grade, 3 - “ secondary education or 4 - “ higher education)
8.  `Fedu` - father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 - “ 5th to 9th grade, 3 - “ secondary education or 4 - “ higher education)
9.  `Mjob` - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')
10. `Fjob` - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')
11. `reason` - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')
12. `guardian` - student's guardian (nominal: 'mother', 'father' or 'other')
13. `traveltime` - home to school travel time (numeric: 1 - \<15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - \>1 hour)
14. `studytime` - weekly study time (numeric: 1 - \<2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - \>10 hours)
15. `failures` - number of past class failures (numeric: n if 1\<=n\<3, else 4)
16. `schoolsup` - extra educational support (binary: yes or no)
17. famsup\` - family educational support (binary: yes or no)
18. `paid` - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)
19. `activities` - extra-curricular activities (binary: yes or no)
20. `nursery` - attended nursery school (binary: yes or no)
21. `higher` - wants to take higher education (binary: yes or no)
22. `internet` - Internet access at home (binary: yes or no)
23. `romantic` - with a romantic relationship (binary: yes or no)
24. `famrel` - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)
25. `freetime` - free time after school (numeric: from 1 - very low to 5 - very high)
26. `goout` - going out with friends (numeric: from 1 - very low to 5 - very high)
27. `Dalc` - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)
28. `Walc` - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)
29. `health` - current health status (numeric: from 1 - very bad to 5 - very good)
30. `absences` - number of school absences (numeric: from 0 to 93)

These columns represent the grades:

-   G1 - first period grade (numeric: from 0 to 20)
-   G2 - second period grade (numeric: from 0 to 20)
-   G3 - final grade (numeric: from 0 to 20, output target)

*Attribution*: The dataset variable description is copied as original from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/320/student+performance).

### Data Loading, Wrangling and Summary

Let's start by loading the data and have an initial view of data set structure.

The file is a `.csv` file with `;` as delimiter. Let's use `pandas`to read it in.

```{python}
# | echo: false
student_performance = pd.read_csv(Path('../data/raw/student-mat.csv'), sep=';')
```

This provides an overview of the data set with 33 columns, each representing student attributes such as age, gender, study time, grades, and parental details.

Let's get some information on the data set to better understand it.

```{python}
# | echo: false
student_performance.head()
```

```{python}
# | echo: false
student_performance.info()
```

The data set contains 395 observations and 33 columns covering different aspects of student demographics, academic and behavioral traits.

We can see that there is no missing values. There is not need to handle NAs.

The data set includes categorical (school, sex, Mjob) and numerical (age, G1, G2, G3) features.

There is a large range of features but not all of them are necessary for this analysis. Let's proceed and select only the necessary ones.

Let's selected the following key columns:

-   Demographic attributes: sex, age
-   Academic Attributes: studytime, failures, G3 (grades for three terms)
-   Behavioral Attributes: goout (socializing), Dalc (weekday alcohol consumption), Walc (weekend alcohol consumption)

We will also split the dataset into train and test set with a 80/20 ratio. We also set `random_state=123` for reproducibility.

#### Data Validation Checks

From heatmap shown in @fig-missingness-heatmap, we observe no missing values, suggesting the dataset is entirely complete.

![Missing Values Heatmap](../results/figures/validate/missingness_heatmap.png){#fig-missingness-heatmap width="50%"}

The histogram in @fig-target-dist-hist visualizes the spread of the target variable. This distribution is critical to understanding how the target behaves and whether any transformations are needed to ensure better model performance.

![Distribution of the target variable](../results/figures/validate/target_distribution_histogram.png){#fig-target-dist-hist width="50%"}

#### Checking for Outliers

There are few outliers in `failures`, `Dalc`, `age`, `studytime`, as shown in @fig-boxplots. These outliers are relatively few compared to the 395 entries, but could still influence model results. We will apply a `StandardScaler` transformation to the numeric variables, the effect of these outliers will be minimized. Therefore, we will not drop or modify these outliers at this step.

![Visualization of Outliers](../results/figures/validate/boxplots.png){#fig-boxplots}

```{python}
# | echo: false
train_df = pd.read_csv("../data/processed/train_df.csv")
train_df.info()
```

Let's get a summary of the training set we are going to use for the analysis.

```{python}
# | echo: false
#| label: tbl-summary
#| tbl-cap: Summary statistics for columns 
Markdown(train_df.describe().to_markdown(index = True))
```

Key takeaways from summary statistics from @tbl-summary:

-   Final grades `G3` range from `0` to `20`, with an average of around `10.26`.
-   The average study time is about `2.05` hours.
-   Most students have zero reported failures.
-   Alcohol consumption (Dalc and Walc) and socializing habits (goout) appear to vary across the student population.

Let's create a visualization to explore the final grades `G3` distribution. We will use a histogram as it allows us to see the spread.

![Distribution of Final Grades (G3)](../results/figures/eda/g3_dist.png){#fig-g3-dist}

From @fig-g3-dist, The histogram shows that most students achieve grades between 8 and 15, with fewer students scoring very low or very high.

![Density plot for each numeric columns](../results/figures/eda/density_plots.png){#fig-density-plot width="80%" height="80%"}


Some interesting observations from @fig-density-plot :

-   The distirbution of the grade `G3` is somewhat bell-shaped.
-   Most student do not consume alcohol, or very minimally.
-   Most student studies around 2-5 hours a week and most of them also did not fail any previous classes.

![Correlation matrices for each numeric column](../results/figures/eda/corr_mat.png){#fig-corr-plot width="50%" height="50%"}

Some interesting observations from @fig-corr-plot:

-   Alcohol consumptions are somewhat negatively correlated with grades
-   Study time are somewhat positively correlated with grades/

### Analysis

We begin our analysis by preparing the data, splitting it into features and target variables for both training and testing. To establish a baseline for comparison, we first fit a DummyRegressor and evaluate its performance, providing a benchmark against which to measure model improvements. Following this, we preprocess the data by distinguishing between categorical and numerical features, applying scaling to numeric features to standardize their range and one-hot encoding to categorical variables to make them interpretable by the model.

Next, we incorporate Ridge regression into a pipeline. Ridge regression is particularly well-suited for this task because it balances model simplicity and predictive performance by penalizing large coefficients. This helps to address potential multicollinearity in the features, ensuring that no single variable disproportionately influences the model while retaining interpretability. To further optimize performance, we fine-tune the Ridge model's hyperparameters using grid search with 5-fold cross-validation, a robust approach for mitigating overfitting and ensuring that the model generalizes well to unseen data.

Finally, we evaluate the Ridge model on the test set, analyzing the observed versus predicted values to assess its predictive accuracy. We also review the cross-validation results to gauge consistency and reliability across different subsets of the data. 

### Model Evaluation

The @tbl-metrics below summarizes the performance metrics of the model on the test dataset. The metrics we use are MSE, RMSE, and MAE. 

- Mean Squared Error (MSE): The average of squared differences between predicted and actual values, giving more weight to larger errors.
- Root Mean Squared Error (RMSE): The square root of MSE, expressing errors in the same units as the data.
- Mean Absolute Error (MAE): The average absolute difference between predicted and actual values, showing overall prediction accuracy.

We use these metrics to evaluate model performance and understand how well predictions align with actual values, with each providing unique insights into error magnitude and distribution.

```{python}
#| label: tbl-metrics
#| tbl-cap: Performance metrics on test data
#| echo: false
Markdown(metrics_table.to_markdown(index = False))
```
Next, we analyze the coefficients of the Ridge regression model. The @tbl-coefficients shows the values of the coefficients, which indicate the importance of each feature in predicting the target variable.

```{python}
#| label: tbl-coefficients
#| tbl-cap: Coefficients of Ridge model
#| echo: false

coeffs_table = pd.read_csv("../results/table/coefficients/ridge_coefficients.csv")
Markdown(coeffs_table.to_markdown(index = False))
```

The following @fig-coefficients visualizes the coefficients of the Ridge regression model. Features with higher absolute coefficients have more impact on the model's predictions.

![Ridge regression coefficients.](../results/figures/coefficients_plot.png){#fig-coefficients width="60%"}

## Results & Discussion

The Ridge Regression model, with tuned hyperparameters, demonstrated well predictive capabilities on student’s math performance. The optimal hyperparameter for Ridge was found to be **alpha = `{python} best_alpha`**, and the **best cross-validation MSE** score is approximately **`{python} best_score`**. This indicates a strong predictive accuracy during the model's validation phase.

The Ridge coefficients suggest that student performance is influenced by a mix of academic and behavioral factors. Among the features, study time has the greatest positive impact on the final grade, indicating that students who dedicate more time to studying tend to perform better. Gender (male) also shows a strong positive influence, suggesting a notable difference in performance between genders.

In contrast, failures have the most significant negative effect, reflecting that prior academic setbacks strongly detract from final grades. Social behaviors like going out and weekday alcohol consumption (Dalc) also have negative influences, albeit to a lesser extent. Interestingly, weekend alcohol consumption (Walc) shows a small positive effect. Lastly, age exerts a slight negative influence, suggesting that older students in this context may face additional challenges.

Based on the evaluation on the test set, the model achieved the following performance metrics:

-   Mean Squared Error (MSE): `{python} mse`
-   Root Mean Squared Error (RMSE): `{python} rmse`
-   Mean Absolute Error (MAE): `{python} mae`

These evaluation metrics indicate that the model demonstrates reasonable accuracy in predicting students' final grades, with an RMSE of `{python} rmse` suggesting that, on average, the model's predictions deviate from actual grades by about `{python} rmse` points. The MAE of `{python} mae` further highlights that most errors are relatively small. However, there is still room for improvement since the model is not fully capturing the underlying patterns in the data.

To enhance performance, we could consider experimenting with alternative modeling techniques, such as tree-based algorithms or neural networks, which might better capture potential non-linear relationships and complex feature interactions. Additionally, feature engineering, such as incorporating interaction terms or applying transformations to certain variables, could help the model better align with the true data distribution.

Another avenue for improvement is to provide confidence intervals for predictions. This would not only enhance the interpretability and reliability of the model but also enable stakeholders to better assess the uncertainty associated with individual predictions. Overall, while the model provides a solid baseline, these enhancements could make it more robust and actionable for practical applications.

## References